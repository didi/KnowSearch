# Integration tests for Korean analysis components
#
---
"Analyzer":
    - do:
        indices.analyze:
          body:
            text:         뿌리가 깊은 나무
            analyzer:     nori
    - length: { tokens: 3 }
    - match:  { tokens.0.token: 뿌리 }
    - match:  { tokens.1.token: 깊 }
    - match:  { tokens.2.token: 나무 }
---
"Tokenizer":
    - do:
        indices.analyze:
          body:
            text:         뿌리가 깊은 나무
            tokenizer:    nori_tokenizer
    - length: { tokens: 5 }
    - match:  { tokens.0.token: 뿌리 }
    - match:  { tokens.1.token: 가  }
    - match:  { tokens.2.token: 깊  }
    - match:  { tokens.3.token: 은  }
    - match:  { tokens.4.token: 나무 }
---
"Part of speech filter":
    - do:
        indices.analyze:
          body:
            text:         뿌리가 깊은 나무
            tokenizer:    nori_tokenizer
            filter:       [nori_part_of_speech]
    - length: { tokens: 3 }
    - match:  { tokens.0.token: 뿌리 }
    - match:  { tokens.1.token: 깊  }
    - match:  { tokens.2.token: 나무 }
---
"Reading filter":
    - do:
        indices.analyze:
          body:
            text:         鄕歌
            tokenizer:    nori_tokenizer
            filter:       [nori_readingform]
    - length: { tokens: 1 }
    - match:  { tokens.0.token: 향가 }
