## Smoke tests for char filters included in the analysis-common module

"html_strip":
    - do:
        indices.analyze:
          body:
            text: <html>test<yyy>foo</yyy></html>
            tokenizer: keyword
            char_filter:
              - type: html_strip
                escaped_tags: ["xxx", "yyy"]
                read_ahead: 1024
    - length: { tokens: 1 }
    - match:  { tokens.0.token: "\ntest<yyy>foo</yyy>\n" }

---
"pattern_replace":
    - do:
        indices.analyze:
          body:
            text: sample6 sample1
            tokenizer: keyword
            char_filter:
              - type: pattern_replace
                pattern: sample(.*)
                replacement: replacedSample $1
    - length: { tokens: 1 }
    - match:  { tokens.0.token: "replacedSample 6 sample1" }

---
"mapping":
    - do:
        indices.analyze:
          body:
            text: jeff quit phish
            tokenizer: keyword
            char_filter:
              - type: mapping
                mappings: ["ph => f", "qu => q"]
    - length: { tokens: 1 }
    - match:  { tokens.0.token: "jeff qit fish" }

    - do:
        indices.analyze:
          body:
            text: jeff quit phish
            explain: true
            tokenizer: keyword
            char_filter:
              - type: mapping
                mappings: ["ph => f", "qu => q"]
    - match:  { detail.custom_analyzer: true }
    - length: { detail.charfilters.0.filtered_text: 1 }
    - match:  { detail.charfilters.0.filtered_text.0: "jeff qit fish" }
    - length: { detail.tokenizer.tokens: 1 }
    - match:  { detail.tokenizer.tokens.0.token: "jeff qit fish" }
    - match:  { detail.tokenizer.tokens.0.start_offset: 0 }
    - match:  { detail.tokenizer.tokens.0.end_offset: 15 }
    - match:  { detail.tokenizer.tokens.0.position: 0 }
