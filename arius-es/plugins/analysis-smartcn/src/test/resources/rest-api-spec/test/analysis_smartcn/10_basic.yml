# Integration tests for Smart Chinese analysis components
#
"Tokenizer":
    - do:
        indices.analyze:
          body:
            text:         我购买了道具和服装。
            tokenizer:    smartcn_tokenizer
    - length: { tokens: 7 }
    - match:  { tokens.0.token: 我  }
    - match:  { tokens.1.token: 购买 }
    - match:  { tokens.2.token: 了 }
    - match:  { tokens.3.token: 道具 }
    - match:  { tokens.4.token: 和 }
    - match:  { tokens.5.token: 服装 }
    - match:  { tokens.6.token: "," }
---
"Analyzer":
    - do:
        indices.analyze:
          body:
            text:         我购买了道具和服装。
            analyzer:     smartcn
    - length: { tokens: 6 }
    - match:  { tokens.0.token: 我  }
    - match:  { tokens.1.token: 购买 }
    - match:  { tokens.2.token: 了 }
    - match:  { tokens.3.token: 道具 }
    - match:  { tokens.4.token: 和 }
    - match:  { tokens.5.token: 服装 }
